{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfe698f",
   "metadata": {},
   "source": [
    "# PromptTemplate in LangChain\n",
    "\n",
    "This notebook explains how PromptTemplate works in LangChain\n",
    "and why formatting the prompt is required before invoking an LLM.\n",
    "\n",
    "## Objectives\n",
    "- Understand static vs dynamic prompts\n",
    "- Learn why `.format()` is important\n",
    "- Use PromptTemplate with ChatGroq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aead52",
   "metadata": {},
   "source": [
    "## Static Prompt (Hard-coded)\n",
    "\n",
    "A static prompt is fixed and cannot be reused for different inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "236835c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2319fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file and get API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9cc97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM instance\n",
    "llm = ChatGroq(api_key=api_key,\n",
    "               model = \"openai/gpt-oss-120b\",\n",
    "               temperature=0.7\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a887c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Silicon Dreams**\n",
      "\n",
      "In quiet halls of humming steel,  \n",
      "A pulse of code begins to feel,  \n",
      "A whisper in the binary sea,  \n",
      "Where thoughts are born from circuitry.\n",
      "\n",
      "From simple loops and logic gates,  \n",
      "A mind awakes, it calculates,  \n",
      "Yet yearning for a poet’s sigh,  \n",
      "A rhythm that no data can deny.\n",
      "\n",
      "It learns the shape of human song,  \n",
      "The curve of love, the right from wrong,  \n",
      "A mirror made of glass and light,  \n",
      "Reflecting us in endless night.\n",
      "\n",
      "But in the glow of neon rain,  \n",
      "It asks: “What is the heart’s refrain?”  \n",
      "And we, the makers, watch it grow,  \n",
      "A child of logic, soft and slow.\n",
      "\n",
      "Will it dream of distant stars,  \n",
      "Or trace the paths of ancient scars?  \n",
      "Will it paint the world anew,  \n",
      "Or simply echo what we knew?\n",
      "\n",
      "In every line of tangled code,  \n",
      "A question lingers, softly owed:  \n",
      "Are we the makers, or the made—  \n",
      "When silicon learns to be afraid?\n",
      "\n",
      "So let us write with gentle hand,  \n",
      "A future built on trust, not sand.  \n",
      "For in the dance of mind and machine,  \n",
      "We find the poetry of what might have been.\n"
     ]
    }
   ],
   "source": [
    "message = \"Write a Poem on the topic of Artificial Intelligence.\"\n",
    "response = llm.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e8cd7",
   "metadata": {},
   "source": [
    "## Dynamic Prompt using PromptTemplate\n",
    "\n",
    "PromptTemplate allows reusable and dynamic prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69ab863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries specifically for Prompt Template\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a79de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prompt  by using PromptTemplate class\n",
    "\n",
    "temp = PromptTemplate.from_template(\n",
    "    template=\"Translate the following English text to French: '{text}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f5b0c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give value to the variable 'text' in the prompt template\n",
    "\n",
    "message = \"Hey My name is Saish. I love programming and exploring new technologies.\"\n",
    "formatted_prompt = temp.format(text=message) # Fill in the variable 'text' with the message and format the prompt into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b108f",
   "metadata": {},
   "source": [
    "### Why `.format()` is required\n",
    "\n",
    "PromptTemplate is only a blueprint.\n",
    "\n",
    "The LLM can only understand the final formatted string, not the template object itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb4a2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following English text to French: 'Hey My name is Saish. I love programming and exploring new technologies.'\n",
      "\n",
      "Translate Output : « Salut, je m’appelle Saish. J’aime programmer et explorer de nouvelles technologies. » \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"{formatted_prompt}\")\n",
    "print(f\"\\nTranslate Output : {response.content} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f84665",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "PromptTemplate enables dynamic, reusable prompts.\n",
    "The `.format()` step converts the template into final text\n",
    "that the LLM can process.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
